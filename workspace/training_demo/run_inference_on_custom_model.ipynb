{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading the saved_model(change the path according to your directory names)\n",
    "import tensorflow as tf\n",
    "import time\n",
    "from object_detection.utils import label_map_util\n",
    "from object_detection.utils import visualization_utils as viz_utils\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_TO_SAVED_MODEL=\"exported-models/my_centernet_fpn/saved_model\"\n",
    "# Load saved model and build the detection function\n",
    "detect_fn=tf.saved_model.load(PATH_TO_SAVED_MODEL)\n",
    "\n",
    "\n",
    "#Loading the label_map\n",
    "category_index=label_map_util.create_category_index_from_labelmap(\"data/label_map.pbtxt\",use_display_name=True)\n",
    "\n",
    "#Loading the image\n",
    "img=['test_images/aug_misc_2.png']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image_into_numpy_array(path):\n",
    "    return np.array(Image.open(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running inference for test_images/aug_misc_2.png... WARNING:tensorflow:8 out of the last 9 calls to <function recreate_function.<locals>.restored_function_body at 0x7fe6ded7a310> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "visualize_boxes_and_labels_on_image_array() missing 2 required positional arguments: 'scores' and 'category_index'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-46-267379ddd667>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mimage_np_with_detections\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimage_np\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     viz_utils.visualize_boxes_and_labels_on_image_array(\n\u001b[0m\u001b[1;32m     15\u001b[0m           \u001b[0mimage_np_with_detections\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m           \u001b[0mdetections\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'detection_boxes'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: visualize_boxes_and_labels_on_image_array() missing 2 required positional arguments: 'scores' and 'category_index'"
     ]
    }
   ],
   "source": [
    "for image_path in img:\n",
    "    print('Running inference for {}... '.format(image_path), end='')\n",
    "    image_np=load_image_into_numpy_array(image_path)\n",
    "    input_tensor=tf.convert_to_tensor(image_np)\n",
    "    input_tensor=input_tensor[tf.newaxis, ...]\n",
    "    detections=detect_fn(input_tensor)\n",
    "    num_detections=int(detections.pop('num_detections'))\n",
    "    detections={key:value[0,:num_detections].numpy()\n",
    "    for key,value in detections.items()}\n",
    "    detections['num_detections']=num_detections\n",
    "    detections['detection_classes'] = detections['detection_classes'].astype(np.int64)\n",
    "    image_np_with_detections=image_np.copy()\n",
    "\n",
    "    viz_utils.visualize_boxes_and_labels_on_image_array(\n",
    "          image_np_with_detections,\n",
    "          detections['detection_boxes'],\n",
    "          detections['detection_classes'],\n",
    "          detections['detection_scores'],\n",
    "          category_index,\n",
    "          use_normalized_coordinates=True,\n",
    "          max_boxes_to_draw=3,     \n",
    "          min_score_thresh=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.grid(False)\n",
    "plt.imshow(image_np_with_detections)\n",
    "plt.show()\n",
    "#cv2.imwrite(\"frame.jpg\", image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
